arguments: src/train_softmax.py --logs_base_dir /home/prixgen-gpu/Desktop/FaceGen/facenet/logs/ --models_base_dir /home/prixgen-gpu/Desktop/FaceGen/facenet/src/models/ --data_dir /home/prixgen-gpu/Desktop/FaceGen/facenet/src/align/aligned_faces/ --image_size 160 --model_def models.inception_resnet_v1 --optimizer ADAM --learning_rate -1 --max_nrof_epochs 150 --keep_probability 0.8 --random_crop --random_flip --use_fixed_image_standardization --learning_rate_schedule_file data/learning_rate_schedule_classifier_casia.txt --weight_decay 5e-4 --embedding_size 512 --lfw_distance_metric 1 --lfw_use_flipped_images --lfw_subtract_mean --validation_set_split_ratio 0.05 --validate_every_n_epochs 5 --prelogits_norm_loss_factor 5e-4
--------------------
tensorflow version: 2.6.0
--------------------
git hash: b'ebb5799bafb0644327034f87724661404f264963'
--------------------
b'diff --git a/contributed/cluster.py b/contributed/cluster.py\nindex 6bd1899..3fc6d44 100644\n--- a/contributed/cluster.py\n+++ b/contributed/cluster.py\n@@ -34,8 +34,12 @@ import sys\n import argparse\n import facenet\n import align.detect_face\n+import matplotlib.pyplot as plt\n+from PIL import Image\n+import imageio\n from sklearn.cluster import DBSCAN\n-\n+import tensorflow.compat.v1 as tf\n+tf.disable_v2_behavior()\n \n def main(args):\n     pnet, rnet, onet = create_network_face_detection(args.gpu_memory_fraction)\n@@ -95,7 +99,8 @@ def main(args):\n                     print(\'Saving largest cluster (Cluster: {})\'.format(largest_cluster))\n                     cnt = 1\n                     for i in np.nonzero(labels == largest_cluster)[0]:\n-                        misc.imsave(os.path.join(args.out_dir, str(cnt) + \'.png\'), images[i])\n+                        imageio.imwrite(os.path.join(args.out_dir, str(cnt) + \'.png\'), images[i])\n+                        #misc.imsave(os.path.join(args.out_dir, str(cnt) + \'.png\'), images[i])\n                         cnt += 1\n                 else:\n                     print(\'Saving all clusters\')\n@@ -106,11 +111,13 @@ def main(args):\n                         if not os.path.exists(path):\n                             os.makedirs(path)\n                             for j in np.nonzero(labels == i)[0]:\n-                                misc.imsave(os.path.join(path, str(cnt) + \'.png\'), images[j])\n+                                imageio.imwrite(os.path.join(path, str(cnt) + \'.png\'), images[j])\n+                                #misc.imsave(os.path.join(path, str(cnt) + \'.png\'), images[j])\n                                 cnt += 1\n                         else:\n                             for j in np.nonzero(labels == i)[0]:\n-                                misc.imsave(os.path.join(path, str(cnt) + \'.png\'), images[j])\n+                                imageio.imwrite(os.path.join(path, str(cnt) + \'.png\'), images[j])\n+                                #misc.imsave(os.path.join(path, str(cnt) + \'.png\'), images[j])\n                                 cnt += 1\n \n \n@@ -121,12 +128,12 @@ def align_data(image_list, image_size, margin, pnet, rnet, onet):\n \n     img_list = []\n \n-    for x in xrange(len(image_list)):\n+    for x in range(len(image_list)):\n         img_size = np.asarray(image_list[x].shape)[0:2]\n         bounding_boxes, _ = align.detect_face.detect_face(image_list[x], minsize, pnet, rnet, onet, threshold, factor)\n         nrof_samples = len(bounding_boxes)\n         if nrof_samples > 0:\n-            for i in xrange(nrof_samples):\n+            for i in range(nrof_samples):\n                 if bounding_boxes[i][4] > 0.95:\n                     det = np.squeeze(bounding_boxes[i, 0:4])\n                     bb = np.zeros(4, dtype=np.int32)\n@@ -135,7 +142,7 @@ def align_data(image_list, image_size, margin, pnet, rnet, onet):\n                     bb[2] = np.minimum(det[2] + margin / 2, img_size[1])\n                     bb[3] = np.minimum(det[3] + margin / 2, img_size[0])\n                     cropped = image_list[x][bb[1]:bb[3], bb[0]:bb[2], :]\n-                    aligned = misc.imresize(cropped, (image_size, image_size), interp=\'bilinear\')\n+                    aligned = np.array(Image.fromarray(cropped).resize((image_size, image_size), Image.BILINEAR)).astype(np.double)\n                     prewhitened = facenet.prewhiten(aligned)\n                     img_list.append(prewhitened)\n \n@@ -158,7 +165,8 @@ def create_network_face_detection(gpu_memory_fraction):\n def load_images_from_folder(folder):\n     images = []\n     for filename in os.listdir(folder):\n-        img = misc.imread(os.path.join(folder, filename))\n+        img = plt.imread(os.path.join(folder, filename))\n+        #img = misc.imread(os.path.join(folder, filename))\n         if img is not None:\n             images.append(img)\n     return images\ndiff --git a/contributed/face.py b/contributed/face.py\nindex 97b9500..a68aa18 100644\n--- a/contributed/face.py\n+++ b/contributed/face.py\n@@ -36,16 +36,32 @@ import cv2\n import numpy as np\n import tensorflow as tf\n from scipy import misc\n-\n+from PIL import Image\n+import csv\n import align.detect_face\n import facenet\n-\n-\n+from PIL import Image\n+import tensorflow.compat.v1 as tf\n+tf.disable_v2_behavior()\n gpu_memory_fraction = 0.3\n-facenet_model_checkpoint = os.path.dirname(__file__) + "/../model_checkpoints/20170512-110547"\n-classifier_model = os.path.dirname(__file__) + "/../model_checkpoints/my_classifier_1.pkl"\n+facenet_model_checkpoint = "/home/prixgen-gpu/Desktop/FaceGen/facenet/src/models/20210915-185044"\n+classifier_model = "/home/prixgen-gpu/Desktop/FaceGen/facenet/src/models/new_classifier_03_09_2021.pkl"\n debug = False\n-\n+def store_single_disk(image, image_id, label):\n+    """ Stores a single image as a .png file on disk.\n+        Parameters:\n+        ---------------\n+        image       image array, (32, 32, 3) to be stored\n+        image_id    integer unique ID for image\n+        label       image label\n+    """\n+    Image.fromarray(image).save(disk_dir / f"{image_id}.png")\n+\n+    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:\n+        writer = csv.writer(\n+            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL\n+        )\n+        writer.writerow([label])\n \n class Face:\n     def __init__(self):\n@@ -149,7 +165,8 @@ class Detection:\n             face.bounding_box[2] = np.minimum(bb[2] + self.face_crop_margin / 2, img_size[1])\n             face.bounding_box[3] = np.minimum(bb[3] + self.face_crop_margin / 2, img_size[0])\n             cropped = image[face.bounding_box[1]:face.bounding_box[3], face.bounding_box[0]:face.bounding_box[2], :]\n-            face.image = misc.imresize(cropped, (self.face_crop_size, self.face_crop_size), interp=\'bilinear\')\n+            #face.image = misc.imresize(cropped, (self.face_crop_size, self.face_crop_size), interp=\'bilinear\')\n+            face.image = np.array(Image.fromarray(cropped).resize((self.face_crop_size, self.face_crop_size), Image.BILINEAR)).astype(np.double)\n \n             faces.append(face)\n \ndiff --git a/contributed/predict.py b/contributed/predict.py\nindex 8bb10a8..0e272a3 100644\n--- a/contributed/predict.py\n+++ b/contributed/predict.py\n@@ -29,19 +29,21 @@ from __future__ import print_function\n #----------------------------------------------------\n \n \n-import tensorflow as tf\n+#import tensorflow as tf\n import numpy as np\n import argparse\n import facenet\n import os\n import sys\n import math\n+import imageio\n import pickle\n from sklearn.svm import SVC\n from scipy import misc\n import align.detect_face\n from six.moves import xrange\n-\n+import tensorflow.compat.v1 as tf\n+tf.disable_v2_behavior()\n def main(args):\n   \n     images, cout_per_image, nrof_samples = load_and_align_data(args.image_files,args.image_size, args.margin, args.gpu_memory_fraction)\n@@ -91,7 +93,7 @@ def load_and_align_data(image_paths, image_size, margin, gpu_memory_fraction):\n     img_list = [] \n     count_per_image = []\n     for i in xrange(nrof_samples):\n-        img = misc.imread(os.path.expanduser(image_paths[i]))\n+        img = imageio.imread(os.path.expanduser(image_paths[i]),plugin=\'matplotlib\')\n         img_size = np.asarray(img.shape)[0:2]\n         bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n         count_per_image.append(len(bounding_boxes))\n@@ -103,7 +105,7 @@ def load_and_align_data(image_paths, image_size, margin, gpu_memory_fraction):\n                 bb[2] = np.minimum(det[2]+margin/2, img_size[1])\n                 bb[3] = np.minimum(det[3]+margin/2, img_size[0])\n                 cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                aligned = misc.imresize(cropped, (image_size, image_size), interp=\'bilinear\')\n+                aligned = np.array(Image.fromarray(cropped).resize((self.face_crop_size, self.face_crop_size), Image.BILINEAR)).astype(np.double)\n                 prewhitened = facenet.prewhiten(aligned)\n                 img_list.append(prewhitened)\t\t\n     images = np.stack(img_list)\ndiff --git a/contributed/real_time_face_recognition.py b/contributed/real_time_face_recognition.py\nindex 8971606..2a51dd9 100644\n--- a/contributed/real_time_face_recognition.py\n+++ b/contributed/real_time_face_recognition.py\n@@ -1,53 +1,128 @@\n # coding=utf-8\n-"""Performs face detection in realtime.\n+"""\n+modified by : Guttappa sajjan\n+Performs face detection and recognition in realtime.\n \n Based on code from https://github.com/shanren7/real_time_face_recognition\n """\n-# MIT License\n-#\n-# Copyright (c) 2017 Fran\xc3\xa7ois Gervais\n-#\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-#\n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-#\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n import argparse\n import sys\n import time\n-\n+import datetime\n import cv2\n-\n+import os\n import face\n-\n-\n+from datetime import date\n+from datetime import datetime\n+import pandas as pd\n+\n+from PIL import Image\n+import csv\n+import errno\n+import xlsxwriter\n+import numpy as np\n+from imutils.video import VideoStream\n+from tensorflow.keras.preprocessing import image\n+import os\n+#######\n+os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"  \n+os.environ["CUDA_VISIBLE_DEVICES"]="0"\n+ts = time.time()\n+st_main = str(date.today())\n+#dir_name=\'Attendance\'\n+# creating a folder named data\n+os.chdir(\'Attendance/\')\n+try:\n+    if not os.path.exists(st_main):\n+        os.makedirs(st_main)\n+        ### cd to the folder\n+        os.chdir(st_main)\n+    else:\n+        #os.makedirs(\'Attendance/\'+st_main)\n+        ### cd to the folder\n+        os.chdir(st_main)\n+\n+except OSError as e:\n+    if e.errno != errno.EEXIST:\n+        raise   \n+    # time.sleep might help here\n+    pass\n+########\n+\n+def store_single_disk(image, label):\n+    """ \n+    @author : Guttappa Sajjan\n+    Stores a single image as a .png file on disk.\n+        Parameters:\n+        ---------------\n+        image       image array, (32, 32, 3) to be stored\n+        label       image label\n+    """\n+    ts = time.time()\n+    st = datetime.fromtimestamp(ts).strftime(\'%d-%m-%Y_%H-%M-%S\')\n+    Image.fromarray(image).save(f"{label}_{st}.png")\n+\n+#########3\n+def mark_attendance(csvData):\n+    with open(\'attendance.csv\', \'a\') as csvFile:\n+        writer = csv.writer(csvFile)\n+        writer.writerows(csvData)\n+        rows = open(\'attendance.csv\').read().split(\'\\n\')\n+        newrows = []\n+        for row in rows:\n+            if row not in newrows:\n+                newrows.append(row)\n+\n+        csvFile = open(\'FinalAttendance.csv\', \'w\')\n+        csvFile.write(\'\\n\'.join(newrows))\n+        #csvFile.to_excel (\'FinalAttendance.xlsx\', index = None, header=True)\n+        # df = pd.read_csv(\'FinalAttendance.csv\')\n+        # df.to_excel(\'FinalAttendance.xlsx\', sheet_name=\'gkz\', index=True)  # index=True to write row index\n+        csvFile.close()\n+\n+#########            \n def add_overlays(frame, faces, frame_rate):\n+\n     if faces is not None:\n+        #main_dict={}\n         for face in faces:\n             face_bb = face.bounding_box.astype(int)\n+            # if face_bb[2]>130:\n             cv2.rectangle(frame,\n-                          (face_bb[0], face_bb[1]), (face_bb[2], face_bb[3]),\n-                          (0, 255, 0), 2)\n+                      (face_bb[0], face_bb[1]), (face_bb[2], face_bb[3]),\n+                      (0, 255, 0), 2)\n+\n             if face.name is not None:\n                 cv2.putText(frame, face.name, (face_bb[0], face_bb[3]),\n-                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0),\n+                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255),\n                             thickness=2, lineType=2)\n \n-    cv2.putText(frame, str(frame_rate) + " fps", (10, 30),\n-                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0),\n-                thickness=2, lineType=2)\n+                date = datetime.fromtimestamp(ts).strftime(\'%Y-%m-%d\')\n+                #timeStamp = datetime.now().strftime(\'%H:%M:%S\')\n+                timeStamp = time.strftime("%-I:%M %p") ##%r for seconds and IST print\n+\n+                #attendance.loc[len(attendance)] = [face.name, date, timeStamp]\n+                #print(attendance)\n+\n+            crop_face = frame[face_bb[1]:face_bb[1]+face_bb[3], face_bb[0]:face_bb[0]+face_bb[2]]\n+\n+            csvData = [[\'Employees_Name\', \'Login_Date\',\'Login_Time\'], [face.name, date,timeStamp]]\n+            mark_attendance(csvData)\n+            start=time.time()\n+            grayscale = False\n+            target_size=(224, 224)\n+            if grayscale == True:\n+                img = cv2.cvtColor(crop_face, cv2.COLOR_BGR2GRAY)\n+                \n+            crop_face = cv2.resize(crop_face, target_size)\n+            #img_pixels = image.img_to_array(crop_face)\n+            #img_pixels = np.expand_dims(img_pixels, axis = 0)\n+            #img_pixels /= 255 #normalize input in [0, 1]\n+            # count=0\n+            # if (time.time() - start > 3):\n+            store_single_disk(crop_face, face.name)\n+                # count+=1\n+\n \n \n def main(args):\n@@ -56,7 +131,8 @@ def main(args):\n     frame_rate = 0\n     frame_count = 0\n \n-    video_capture = cv2.VideoCapture(0)\n+    #video_capture = cv2.VideoCapture(\'/home/guttappa/Desktop/Guttappa/filename.avi\')\n+    video_capture = VideoStream(\'rtsp://admin:Ashlesha123@192.168.0.170\').start()\n     face_recognition = face.Recognition()\n     start_time = time.time()\n \n@@ -66,31 +142,38 @@ def main(args):\n \n     while True:\n         # Capture frame-by-frame\n-        ret, frame = video_capture.read()\n+        frame = video_capture.read()\n+        frame=cv2.resize(frame,(620,480))\n+        #frame =cv2.imread(\'/home/guttappa/Downloads/IMG-20210202-WA0008.jpg\')\n \n         if (frame_count % frame_interval) == 0:\n             faces = face_recognition.identify(frame)\n \n-            # Check our current fps\n-            end_time = time.time()\n-            if (end_time - start_time) > fps_display_interval:\n-                frame_rate = int(frame_count / (end_time - start_time))\n-                start_time = time.time()\n-                frame_count = 0\n-\n+            # # Check our current fps\n+            # end_time = time.time()\n+            # if (end_time - start_time) > fps_display_interval:\n+            #     frame_rate = int(frame_count / (end_time - start_time))\n+            #     start_time = time.time()\n+            #     frame_count = 0\n+            \n         add_overlays(frame, faces, frame_rate)\n+        # store_single_disk(frame, image_id, label)\n \n         frame_count += 1\n-        cv2.imshow(\'Video\', frame)\n-\n+        ####adding date and time to the frame\n+        #timestamp = datetime.now()\n+        # tm = timestamp.strftime("%A %d %B %Y %I:%M:%S%p")        \n+        # cv2.putText(frame, tm, (10, frame.shape[0] - 10),\n+        # cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n+        cv2.imshow(\'Recognition stream...\', frame)\n         if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n             break\n \n     # When everything is done, release the capture\n-    video_capture.release()\n+    #video_capture.release()\n+    video_capture.stop()\n     cv2.destroyAllWindows()\n \n-\n def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n \ndiff --git a/src/facenet.py b/src/facenet.py\nindex e96c9ea..81c7c37 100644\n--- a/src/facenet.py\n+++ b/src/facenet.py\n@@ -29,12 +29,14 @@ from __future__ import print_function\n \n import os\n from subprocess import Popen, PIPE\n-import tensorflow as tf\n+#import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n+tf.disable_v2_behavior()\n import numpy as np\n from scipy import misc\n from sklearn.model_selection import KFold\n from scipy import interpolate\n-from tensorflow.python.training import training\n+#from tensorflow.python.training import training\n import random\n import re\n from tensorflow.python.platform import gfile\ndiff --git a/src/freeze_graph.py b/src/freeze_graph.py\nindex 3584c18..ef83bb4 100644\n--- a/src/freeze_graph.py\n+++ b/src/freeze_graph.py\n@@ -34,7 +34,8 @@ import os\n import sys\n import facenet\n from six.moves import xrange  # @UnresolvedImport\n-\n+import tensorflow.compat.v1 as tf\n+tf.disable_v2_behavior()\n def main(args):\n     with tf.Graph().as_default():\n         with tf.Session() as sess:\ndiff --git a/src/models/inception_resnet_v1.py b/src/models/inception_resnet_v1.py\nindex 475e81b..63f6178 100644\n--- a/src/models/inception_resnet_v1.py\n+++ b/src/models/inception_resnet_v1.py\n@@ -24,8 +24,10 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow as tf\n-import tensorflow.contrib.slim as slim\n \n+import tensorflow.compat.v1 as tf\n+import tf_slim as slim\n+tf.disable_v2_behavior()\n # Inception-Resnet-A\n def block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n     """Builds the 35x35 resnet block."""\ndiff --git a/src/models/inception_resnet_v2.py b/src/models/inception_resnet_v2.py\nindex 0fb176f..5a6bdde 100644\n--- a/src/models/inception_resnet_v2.py\n+++ b/src/models/inception_resnet_v2.py\n@@ -25,7 +25,8 @@ from __future__ import print_function\n \n import tensorflow as tf\n import tensorflow.contrib.slim as slim\n-\n+import tensorflow.compat.v1 as tf\n+tf.disable_v2_behavior()\n # Inception-Resnet-A\n def block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n     """Builds the 35x35 resnet block."""\ndiff --git a/src/train_softmax.py b/src/train_softmax.py\nindex 6b0b28b..1c69f7a 100644\n--- a/src/train_softmax.py\n+++ b/src/train_softmax.py\n@@ -39,11 +39,13 @@ import facenet\n import lfw\n import h5py\n import math\n-import tensorflow.contrib.slim as slim\n+import tf_slim as slim\n+#import tensorflow.contrib.slim as slim\n from tensorflow.python.ops import data_flow_ops\n from tensorflow.python.framework import ops\n from tensorflow.python.ops import array_ops\n-\n+import tensorflow.compat.v1 as tf\n+tf.disable_v2_behavior()\n def main(args):\n   \n     network = importlib.import_module(args.model_def)\ndiff --git a/src/train_tripletloss.py b/src/train_tripletloss.py\nindex d6df19a..8f9bc41 100644\n--- a/src/train_tripletloss.py\n+++ b/src/train_tripletloss.py\n@@ -38,11 +38,17 @@ import itertools\n import argparse\n import facenet\n import lfw\n+import tensorflow.compat.v1 as tf\n \n+tf.disable_v2_behavior()\n from tensorflow.python.ops import data_flow_ops\n \n from six.moves import xrange  # @UnresolvedImport\n \n+import os\n+os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"  \n+os.environ["CUDA_VISIBLE_DEVICES"]="0"\n+\n def main(args):\n   \n     network = importlib.import_module(args.model_def)\n@@ -105,7 +111,9 @@ def main(args):\n             images = []\n             for filename in tf.unstack(filenames):\n                 file_contents = tf.read_file(filename)\n+                #image = tf.to_float(file_contents)\n                 image = tf.image.decode_image(file_contents, channels=3)\n+                image = tf.to_float(image)\n                 \n                 if args.random_crop:\n                     image = tf.random_crop(image, [args.image_size, args.image_size, 3])\n@@ -324,7 +332,7 @@ def sample_people(dataset, people_per_batch, images_per_person):\n     sampled_class_indices = []\n     # Sample images from these classes until we have enough\n     while len(image_paths)<nrof_images:\n-        class_index = class_indices[i]\n+        class_index = class_indices[0]\n         nrof_images_in_class = len(dataset[class_index])\n         image_indices = np.arange(nrof_images_in_class)\n         np.random.shuffle(image_indices)\ndiff --git a/test/triplet_loss_test.py b/test/triplet_loss_test.py\nindex 2648b30..3f15e6b 100644\n--- a/test/triplet_loss_test.py\n+++ b/test/triplet_loss_test.py\n@@ -24,7 +24,8 @@ import unittest\n import tensorflow as tf\n import numpy as np\n import facenet\n-\n+import tensorflow.compat.v1 as tf\n+tf.disable_v2_behavior()\n class DemuxEmbeddingsTest(unittest.TestCase):\n   \n     def testDemuxEmbeddings(self):'